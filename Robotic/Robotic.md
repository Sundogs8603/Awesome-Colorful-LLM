# Robotic

Table of Contents

- [Reading List](#reading-list)
- [Reference](#reference)

## Reading List

| Paper                                                                                    | Base Language Model | Code                                                                                         | Publication | Preprint                                    | Affiliation         |
| ---------------------------------------------------------------------------------------- | ------------------- | -------------------------------------------------------------------------------------------- | ----------- | ------------------------------------------- | ------------------- |
| A Language Agent for Autonomous Driving                                                  | GPT-3.5             | [code](https://github.com/USC-GVL/Agent-Driver)                                                 |             | [2311.10813](https://arxiv.org/abs/2311.10813) | USC                 |
| RT-2: New model translates vision and language into action                               | PaLI-X, PaLM-E      | [blog](https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action) |             |                                             | Deepmind            |
| VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models         | GPT4                | [web](https://voxposer.github.io/)                                                              |             | [2307.05973](https://arxiv.org/abs/2307.05973) | Stanford            |
| Statler: State-Maintaining Language Models for Embodied Reasoning                        | GPT3                |                                                                                              |             | [2306.17840](https://arxiv.org/abs/2306.17840) | TTIC                |
| Chat with the Environment: Interactive Multimodal Perception using Large Language Models | GPT3                |                                                                                              |             | [2303.08268](https://arxiv.org/abs/2303.08268) | Universitat Hamburg |

## Reference

- [Awesome-Robotics-Foundation-Models](https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models)
  > This is the partner repository for the survey paper "Foundation Models in Robotics: Applications, Challenges, and the Future". The authors hope this repository can act as a quick reference for roboticists who wish to read the relevant papers and implement the associated methods. 

- [Awesome-TimeSeries-SpatioTemporal-LM-LLM](https://github.com/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM)
  > A professionally curated list of **Large (Language) Models and Foundation Models (LLM, LM, FM) for Temporal Data (Time Series, Spatio-temporal, and Event Data)** with awesome resources (paper, code, data, etc.), which aims to comprehensively and systematically summarize the recent advances to the best of our knowledge.
  >
- [Awesome-LLM-Robotics](https://github.com/GT-RIPL/Awesome-LLM-Robotics)
  > This repo contains a curative list of papers using Large Language/Multi-Modal Models for Robotics/RL
  >
- [PromptCraft-Robotics](https://github.com/microsoft/PromptCraft-Robotics)
  > The PromptCraft-Robotics repository serves as a community for people to test and share interesting prompting examples for large language models (LLMs) within the robotics domain
  >
- [Awesome-Robotics](https://github.com/ahundt/awesome-robotics)
  > A curated list of awesome links and software libraries that are useful for robots
  >
