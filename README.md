<h1 align="center" class="ui-bar-a"> <img alt="awesome-colorful-ai" src="assets/logo.png" width="60"> Colorful Multimodal Research</h1>

<p align="center">
    <a href="https://awesome.re">
        <img alt="awesome", src="https://awesome.re/badge.svg">
    </a>
</p>

Welcome to our meticulously assembled anthology of vibrant multimodal research, encompassing an array of domains including **Vision**, **Audio**, **Code**, **Agent**, **Robotics**, and **Fundamental Sciences** such as Mathematics. Our collection primarily focuses on the advancements propelled by **large language models (LLMs)**, complemented by an assortment of related collections.

## Table of Contents

- [👀 Vision](#👀-vision)
    - [Image](#🖼-image)
    - [Video](#📺-video)
    - [3D](#📷-3d)
- [👂 Audio](#👂-audio)
- [💻 Code](#💻-code)
- [🔧 Agent](#🔧-agent)
- [🤖 Robotic](#🤖-robotic)
- [🔬 Science](#🔬-science)
    - [Math](#♾️-ai-for-math)
- [🙌 Contributing](#contributing)

## 👀 Vision

### 🖼 Image

Collection of works about Image + LLMs, Diffusion, see [Image](Vision/Image.md) for details

> - Image Understanding
>   - Reading List
>   - Datasets & Benchmarks
> - Image Generation
>   - Reading List
>   - Other Resources
> - Opensource Projects


Related Collections (Understanding)

- [VLM_survey](https://github.com/jingyi0000/VLM_survey) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/jingyi0000/VLM_survey?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/jingyi0000/VLM_survey.svg?style=social&label=Star), This is the repository of "Vision Language Models for Vision Tasks: a Survey", a systematic survey of VLM studies in various visual recognition tasks including image classification, object detection, semantic segmentation, etc.
- [Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/BradyFU/Awesome-Multimodal-Large-Language-Models?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/BradyFU/Awesome-Multimodal-Large-Language-Models.svg?style=social&label=Star), A curated list of Multimodal Large Language Models (MLLMs), including datasets, multimodal instruction tuning, multimodal in-context learning, multimodal chain-of-thought, llm-aided visual reasoning, foundation models, and others. This list will be updated in real time.
- [LLM-in-Vision](https://github.com/DirtyHarryLYL/LLM-in-Vision) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/DirtyHarryLYL/LLM-in-Vision?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/DirtyHarryLYL/LLM-in-Vision.svg?style=social&label=Star), Recent LLM (Large Language Models)-based CV and multi-modal works
- [Awesome-Transformer-Attention](https://github.com/cmhungsteve/Awesome-Transformer-Attention) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/cmhungsteve/Awesome-Transformer-Attention?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/cmhungsteve/Awesome-Transformer-Attention.svg?style=social&label=Star), This repo contains a comprehensive paper list of Vision Transformer & Attention, including papers, codes, and related websites
- [Awesome-Vision-and-Language](https://github.com/sangminwoo/awesome-vision-and-language) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/sangminwoo/awesome-vision-and-language?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/sangminwoo/awesome-vision-and-language.svg?style=social&label=Star), A curated list of awesome vision and language resources
- [Awesome-Multimodal-Research](https://github.com/Eurus-Holmes/Awesome-Multimodal-Research) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/Eurus-Holmes/Awesome-Multimodal-Research?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/Eurus-Holmes/Awesome-Multimodal-Research.svg?style=social&label=Star), This repo is reorganized from Awesome-Multimodal-ML
- [Awesome-Multimodal-ML](https://github.com/pliang279/awesome-multimodal-ml) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/pliang279/awesome-multimodal-ml?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/pliang279/awesome-multimodal-ml.svg?style=social&label=Star), Reading list for research topics in multimodal machine learning

Related Collections (Generation)

- [Awesome-Diffusion-Models](https://github.com/heejkoo/Awesome-Diffusion-Models)![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/heejkoo/Awesome-Diffusion-Models?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/heejkoo/Awesome-Diffusion-Models.svg?style=social&label=Star), This repository contains a collection of resources and papers on Diffusion Models

Tutorials

- [CVPR2023 Tutorial] [Recent Advances in Vision Foundation Models](https://vlp-tutorial.github.io/)
- [CVPR2022 Tutorial] [Recent Advances in Vision-and-Language Pre-training](https://vlp-tutorial.github.io/)


### 📺 Video

Collection of works about Video-Language Pretraining, Video + LLMs, see [Video](Vision/Video.md) for details

> - Video Understanding
>   - Reading List
>   - Pretraining Tasks
>   - Datasets
>     - Pretraining Corpora
>     - Video Instructions
>   - Benchmarks
>     - Common Downstream Tasks
>     - Advanced Downstream Tasks
> - Video Understanding
>   - Reading List

Related Collections (datasets)

- [Awesome-Video-Datasets](https://github.com/xiaobai1217/Awesome-Video-Datasets#Video-and-Language) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/xiaobai1217/Awesome-Video-Datasets?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/xiaobai1217/Awesome-Video-Datasets.svg?style=social&label=Star)

### 📷 3D

Collection of works about 3D+LLM, see [3D](Vision/3D.md) for details

> - Reading List

Related Collections

- [Awesome-LLM-3D](https://github.com/ActiveVisionLab/Awesome-LLM-3D) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/ActiveVisionLab/Awesome-LLM-3D?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/ActiveVisionLab/Awesome-LLM-3D.svg?style=social&label=Star), a curated list of Multi-modal Large Language Model in 3D world Resources
- [Awesome-3D-Vision-and-Language](https://github.com/jianghaojun/Awesome-3D-Vision-and-Language) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/jianghaojun/Awesome-3D-Vision-and-Language?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/jianghaojun/Awesome-3D-Vision-and-Language.svg?style=social&label=Star), A curated list of research papers in 3D visual grounding


## 👂 Audio

Collection of works about audio+LLM, see [Audio](Audio/Audio.md) for details

> - Reading List

Related Collections

- [Audio-AI-Timeline](https://github.com/archinetai/audio-ai-timeline) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/archinetai/audio-ai-timeline?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/archinetai/audio-ai-timeline.svg?style=social&label=Star), Here we will keep track of the latest AI models for waveform based audio generation, starting in 2023!

## 💻 Code

Collection of works about code+LLM, see [Code](Code/code.md) for details.

> - Reading List

Related Collections

- [Awesome-Code-LLM](https://github.com/huybery/Awesome-Code-LLM) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/huybery/Awesome-Code-LLM?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/huybery/Awesome-Code-LLM.svg?style=social&label=Star), An awesome and curated list of best code-LLM for research.

## 🔧 Agent

Collection of works about agent learning, see [Agent](Agents/Agent.md) for details

> - Reading List
> - Projects
> - Applications

Related Collections

- [LLM-Agent-Paper-Digest](https://github.com/XueyangFeng/LLM-Agent-Paper-Digest) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/XueyangFeng/LLM-Agent-Paper-Digest?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/XueyangFeng/LLM-Agent-Paper-Digest.svg?style=social&label=Star), For benefiting the research community and promoting LLM-powered agent direction, we organize papers related to LLM-powered agent that published on top conferences recently
- [LLMAgentPapers](https://github.com/zjunlp/LLMAgentPapers) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/zjunlp/LLMAgentPapers?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/zjunlp/LLMAgentPapers.svg?style=social&label=Star), Must-read Papers on Large Language Model Agents.
- [LLM-Agent-Paper-List](https://github.com/WooooDyy/LLM-Agent-Paper-List) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/WooooDyy/LLM-Agent-Paper-List?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/WooooDyy/LLM-Agent-Paper-List.svg?style=social&label=Star), In this repository, we provide a systematic and comprehensive survey on LLM-based agents, and list some must-read papers.
- [XLang Paper Reading](https://github.com/xlang-ai/xlang-paper-reading) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/xlang-ai/xlang-paper-reading?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/xlang-ai/xlang-paper-reading.svg?style=social&label=Star), Paper collection on building and evaluating language model agents via executable language grounding
- [Awesome-LLMOps](https://github.com/tensorchord/Awesome-LLMOps) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/tensorchord/Awesome-LLMOps?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/tensorchord/Awesome-LLMOps.svg?style=social&label=Star), An awesome & curated list of best LLMOps tools for developers
- [Awesome LLM-Powered Agent](https://github.com/hyp1231/awesome-llm-powered-agent) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/hyp1231/awesome-llm-powered-agent?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/hyp1231/awesome-llm-powered-agent.svg?style=social&label=Star), Awesome things about LLM-powered agents. Papers / Repos / Blogs / ...
- [ToolLearningPapers](https://github.com/thunlp/ToolLearningPapers) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/thunlp/ToolLearningPapers?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/thunlp/ToolLearningPapers.svg?style=social&label=Star), Must-read papers on tool learning with foundation models
- [Awesome-ALM](https://github.com/pbhu1024/awesome-augmented-language-model) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/pbhu1024/awesome-augmented-language-model?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/pbhu1024/awesome-augmented-language-model.svg?style=social&label=Star), This repo collect research papers about leveraging the capabilities of language models, which can be a good reference for building upper-layer applications
- [LLM-powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/), Lil'Log, Overview: panning, memory, tool use

## 🤖 Robotic

Collection of works about audio+LLM, see [Robotic](Robotic/Robotic.md) for details

> - Reading List

Related Collections

- [Awesome-Robotics-Foundation-Models](https://github.com/robotics-survey/Awesome-Robotics-Foundation-Models) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/robotics-survey/Awesome-Robotics-Foundation-Models?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/robotics-survey/Awesome-Robotics-Foundation-Models.svg?style=social&label=Star), This is the partner repository for the survey paper "Foundation Models in Robotics: Applications, Challenges, and the Future". The authors hope this repository can act as a quick reference for roboticists who wish to read the relevant papers and implement the associated methods.
- [Awesome-LLM-Robotics](https://github.com/GT-RIPL/Awesome-LLM-Robotics) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/GT-RIPL/Awesome-LLM-Robotics?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/GT-RIPL/Awesome-LLM-Robotics.svg?style=social&label=Star), This repo contains a curative list of papers using Large Language/Multi-Modal Models for Robotics/RL
- [Awesome-TimeSeries-SpatioTemporal-LM-LLM](https://github.com/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM.svg?style=social&label=Star), A professionally curated list of **Large (Language) Models and Foundation Models (LLM, LM, FM) for Temporal Data (Time Series, Spatio-temporal, and Event Data)** with awesome resources (paper, code, data, etc.), which aims to comprehensively and systematically summarize the recent advances to the best of our knowledge.
- [PromptCraft-Robotics](https://github.com/microsoft/PromptCraft-Robotics) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/microsoft/PromptCraft-Robotics?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/microsoft/PromptCraft-Robotics.svg?style=social&label=Star), The PromptCraft-Robotics repository serves as a community for people to test and share interesting prompting examples for large language models (LLMs) within the robotics domain
- [Awesome-Robotics](https://github.com/ahundt/awesome-robotics) ![GitHub last commit (by committer)](https://img.shields.io/github/last-commit/ahundt/awesome-robotics?style=flat)![Dynamic JSON Badge](https://img.shields.io/github/stars/ahundt/awesome-robotics.svg?style=social&label=Star), A curated list of awesome links and software libraries that are useful for robots

## 🔬 Science

### ♾️ AI for Math

Collection of works about Mathematics + LLMs, see [AI4Math](AI4Science/AI4Math.md) for details

> - Reading List


## Contributing

Please freely create a [pull request](https://github.com/patrick-tssn/Awesome-Colorful-LLM/pulls) or drop me an email: [flagwyx@gmail.com](flagwyx@gmail.com)
