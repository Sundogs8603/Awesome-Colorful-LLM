| Paper                                                        | Base Language Model      | Code                                                         | Publication | Preprint                                       | Affiliation |
| ------------------------------------------------------------ | ------------------------ | ------------------------------------------------------------ | ----------- | ---------------------------------------------- | ----------- |
| ViperGPT: Visual Inference via Python Execution for Reasoning | Codex                    | [ViperGPT](https://github.com/cvlab-columbia/viper%5D(https://docs.qq.com/sheet/DTUlQTWJnRktkS2RC)) |             | [2303.08128](https://arxiv.org/abs/2303.08128) | Columbia    |
| ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions | ChatGPT, Flan-T5 (BLIP2) | [ChatCaptioner](https://github.com/Vision-CAIR/ChatCaptioner%5D(https://docs.qq.com/sheet/DTUlQTWJnRktkS2RC)) |             | [2303.06594](https://arxiv.org/abs/2303.06594) | KAUST       |
| Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models | ChatGPT                  | [Visual ChatGPT](https://github.com/microsoft/visual-chatgpt%5D(https://docs.qq.com/sheet/DTUlQTWJnRktkS2RC)) |             | [2303.04671](https://arxiv.org/abs/2303.04671) | Microsoft   |
| PaLM-E: An Embodied Multimodal Language Model                | PaLM                     |                                                              |             | [2303.03378](https://arxiv.org/abs/2303.03378) | Google      |
| Language Is Not All You Need: Aligning Perception with Language Models | Magneto                  | [KOSMOS-1](https://github.com/microsoft/unilm)               |             | [2302.14045](https://arxiv.org/abs/2302.14045) | Microsoft   |
| BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models | Flan-T5                  | [BLIP2](https://github.com/salesforce/LAVIS/tree/main/projects/blip2%5D(https://docs.qq.com/sheet/DTUlQTWJnRktkS2RC)) |             | [2301.12597](https://arxiv.org/abs/2301.12597) | Salesforce  |
| Language Models are General-Purpose Interfaces               | DeepNorm                 | [METALM](https://github.com/microsoft/unilm%5D(https://docs.qq.com/sheet/DTUlQTWJnRktkS2RC)) |             | [2206.06336](https://arxiv.org/abs/2206.06336) | Microsoft   |
| Flamingo: a Visual Language Model for Few-Shot Learning      | Chinchilla               | [Flamingo](https://github.com/lucidrains/flamingo-pytorch%5D(https://docs.qq.com/sheet/DTUlQTWJnRktkS2RC)) | NIPS 2022   | [2204.14198](https://arxiv.org/abs/2204.14198) | DeepMind    |
| Learning Transferable Visual Models From Natural Language Supervision | Bert                     | [CLIP](https://github.com/openai/CLIP%5D(https://docs.qq.com/sheet/DTUlQTWJnRktkS2RC)) | ICML 2021   | [2103.00020](https://arxiv.org/abs/2103.00020) | OpenAI      |