# Vision

Table of Contents

- [Image](#image)
- [Video](#video)
- [Tutorials](#tutorials)
- [Reference](#reference)
  - [Model](#model)
  - [Dataset](#dataset)

## Image

Collection of works (Reading list, open source collections, etc.) about Image+LLM, see [Image](Image.md) for details

> - Image Understanding
>   - Reading List
>   - Dataset
>   - Benchmarks
> - Image Generation
>   - Reading List

## Video

Collection of works (Reading list, open source collections, etc.) about Video-Language Pretraining/Video+LLM, see [Video](Video.md) for details

> - Reading List
> - Pretraining Tasks
> - Datasets
>   - Pretraining Corpora
> - Benchmarks
>   - Common Downstream Tasks
>   - Advanced Downstream Tasks

## Tutorials

- [CVPR2022 Tutorial] [Recent Advances in Vision-and-Language Pre-training](https://vlp-tutorial.github.io/)

## Reference

*Active curated resources*

### Model:

- [Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)

  > A curated list of Multimodal Large Language Models (MLLMs), including datasets, multimodal instruction tuning, multimodal in-context learning, multimodal chain-of-thought, llm-aided visual reasoning, foundation models, and others. This list will be updated in real time.
  >
- [LLM-in-Vision](https://github.com/DirtyHarryLYL/LLM-in-Vision)

  > Recent LLM (Large Language Models)-based CV and multi-modal works
  >
- [Awesome-Transformer-Attention](https://github.com/cmhungsteve/Awesome-Transformer-Attention)

  > This repo contains a comprehensive paper list of Vision Transformer & Attention, including papers, codes, and related websites
  >
- [Awesome-Vision-and-Language](https://github.com/sangminwoo/awesome-vision-and-language)

  > A curated list of awesome vision and language resources
  >
- [Awesome-Diffusion-Models](https://github.com/heejkoo/Awesome-Diffusion-Models)

  > This repository contains a collection of resources and papers on Diffusion Models
  >
- [Awesome-3D-Vision-and-Language](https://github.com/jianghaojun/Awesome-3D-Vision-and-Language)

  > A curated list of research papers in 3D visual grounding
  >

### Dataset:

- [Awesome-Video-Datasets](https://github.com/xiaobai1217/Awesome-Video-Datasets#Video-and-Language)
  > video datasets
  >
